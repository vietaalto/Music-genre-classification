\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Data analysis}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Class distribution}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Descriptive statistics}{section.2}% 4
\BOOKMARK [1][-]{section.3}{Methods and experiments}{}% 5
\BOOKMARK [2][-]{subsection.3.1}{Data preprocessing}{section.3}% 6
\BOOKMARK [2][-]{subsection.3.2}{Ensemble model and Gradient boosting:}{section.3}% 7
\BOOKMARK [3][-]{subsubsection.3.2.1}{numerical optimization via gradient boosting}{subsection.3.2}% 8
\BOOKMARK [2][-]{subsection.3.3}{XGBoost models }{section.3}% 9
\BOOKMARK [2][-]{subsection.3.4}{ Evaluation: stratified K-fold}{section.3}% 10
\BOOKMARK [2][-]{subsection.3.5}{Tuning hyperparameters - Bayesian optimization vs Randomsearch}{section.3}% 11
\BOOKMARK [3][-]{subsubsection.3.5.1}{Randomsearch}{subsection.3.5}% 12
\BOOKMARK [3][-]{subsubsection.3.5.2}{Bayesian optimization}{subsection.3.5}% 13
\BOOKMARK [2][-]{subsection.3.6}{Experiments}{section.3}% 14
\BOOKMARK [1][-]{section.4}{Results}{}% 15
\BOOKMARK [2][-]{subsection.4.1}{performance measures}{section.4}% 16
\BOOKMARK [2][-]{subsection.4.2}{performance on Kaggle}{section.4}% 17
\BOOKMARK [1][-]{section.5}{Conclusion}{}% 18
\BOOKMARK [1][-]{section.6}{Appendices}{}% 19
\BOOKMARK [1][-]{section*.1}{References}{}% 20
